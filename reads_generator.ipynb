{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = '/opt/anaconda3/bin:/opt/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gnomad_dictionary_2.pickle','rb') as read_file:\n",
    "    normal_var_dict=pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the functions for base change, insertion, deletion\n",
    "def update_sequence(changes_list, seq, offset, start):\n",
    "    \n",
    "    #if list doesn't contain any changes just return the same seq and offset\n",
    "    if len(changes_list) == 1 and changes_list[0] == \"skip\":\n",
    "        return seq, offset\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        #loop over changes list\n",
    "        for i in range(len(changes_list)):\n",
    "            \n",
    "            #do nothing if it is a skip\n",
    "            if changes_list[i] == \"skip\":\n",
    "                continue\n",
    "\n",
    "            #if it's a base change do this:\n",
    "            elif len(changes_list[i][2]) == 1 and changes_list[i][2] != \"-\":\n",
    "                if changes_list[i][2]!=changes_list[i][3]:\n",
    "                    new_base = changes_list[i][3]\n",
    "                else:\n",
    "                    new_base = changes_list[i][4]\n",
    "                ref_pos = int(changes_list[i][1]) -1\n",
    "                adjust = int(offset[ref_pos - start])\n",
    "\n",
    "                seq = seq[0:ref_pos + adjust - start] + new_base + seq[ref_pos + adjust - start + 1:]\n",
    "\n",
    "            #if it's an insertion do this:\n",
    "            elif changes_list[i][2] == \"-\":\n",
    "                if changes_list[i][2]!=changes_list[i][3]:\n",
    "                    new_base = changes_list[i][3]\n",
    "                else:\n",
    "                    new_base = changes_list[i][4]\n",
    "                ref_pos = int(changes_list[i][1]) -1\n",
    "                adjust = int(offset[ref_pos - start])\n",
    "\n",
    "\n",
    "                seq = seq[0:ref_pos + adjust - start + 1] + new_base + seq[ref_pos + adjust - start : 100-len(new_base)]\n",
    "\n",
    "                if len(seq) > 100:\n",
    "                    seq = seq[:100]\n",
    "            \n",
    "                offset= np.add(offset,  np.concatenate((np.zeros(ref_pos-start+1),np.repeat(len(new_base), start+100-ref_pos-1))))\n",
    "                \n",
    "            #if it's a deletion do this:\n",
    "            elif changes_list[i][4]==\"-\" or changes_list[i][3]==\"-\":\n",
    "                new_base = \"\"\n",
    "                \n",
    "                ref_pos = int(changes_list[i][1]) # no -1 here\n",
    "                adjust = int(offset[ref_pos - start])\n",
    "                expected_base = changes_list[i][2]\n",
    "\n",
    "                seq = seq[0:ref_pos + adjust - start] + new_base + seq[ref_pos + adjust -start+len(expected_base):(100-len(new_base)+1)] \n",
    "                \n",
    "                if len(seq) < 100:\n",
    "                    current_end = len(seq) + start - int(offset[len(seq)]) -1\n",
    "                    \n",
    "                    with open('temp_location.bed', 'w') as file:\n",
    "                        file.write(chrom + \"\\t\" + str(current_end) + \"\\t\" + str(current_end+len(expected_base)-len(new_base)))\n",
    "                    additional_sequence = !bedtools getfasta -fi /Volumes/BethMac/hg38/hg38.fa -bed temp_location.bed\n",
    "                    seq = seq + additional_sequence[1]\n",
    "                    !rm temp_location.bed\n",
    "\n",
    "                offset=np.add(offset, np.concatenate((np.zeros(ref_pos-start),np.repeat(-len(expected_base), start+100-ref_pos))))\n",
    "\n",
    "                \n",
    "                \n",
    "        return seq, offset\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the samples list from the TCGA MAF file - here breast cancer\n",
    "os.chdir(\"/Users/beth/Documents/SNV project/gdc_download_20200914_095313.532292/995c0111-d90b-4140-bee7-3845436c3b42\")\n",
    "\n",
    "TCGA_file = \"TCGA.BRCA.mutect.995c0111-d90b-4140-bee7-3845436c3b42.DR-10.0.somatic.maf\"\n",
    "\n",
    "samples = !tail -n +7 $TCGA_file | cut -f16 | sort | uniq\n",
    "\n",
    "current_organ = \"breast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could run the loop once for each tumor type TCGA MAF file ... need to parrallelize \n",
    "\n",
    "#looping over each sample\n",
    "for i in range(len(samples[0:2])):\n",
    "    current_sample = samples[i]\n",
    "    sample_mutations = !grep $current_sample $TCGA_file | tail -n +2 | cut -f5,6,11,12,13\n",
    "    sample_mutations = tuple(map(lambda x: tuple(x.split('\\t')), sample_mutations))\n",
    "    sample_mutations_dict = defaultdict(list)\n",
    "    \n",
    "    #creating sample_mutations_dict\n",
    "    for i in range(len(sample_mutations)):\n",
    "        sample_mutations_dict[sample_mutations[i][0]].append([int(sample_mutations[i][1]), sample_mutations[i][2], sample_mutations[i][3], sample_mutations[i][4]])\n",
    "        \n",
    "    \n",
    "    #looping over each mutation in sample_mutations list of tuples \n",
    "    for i in range(len(sample_mutations)):\n",
    "        current_location = sample_mutations[i]\n",
    "        \n",
    "        #to get 10 windows of 100bp around it (note: hg38 is one position behind both MAF and VCF)\n",
    "        window_starts=[]\n",
    "        for j in range(10):\n",
    "            window = range(int(current_location[1])-100,int(current_location[1])-1)\n",
    "            start = random.choice(list(window))\n",
    "            end = start + 100\n",
    "            chrom = current_location[0]\n",
    "            window_starts.append(start)\n",
    "            with open(\"sample_locations.tmp\", \"a\") as file:\n",
    "                file.write(chrom + \"\\t\" + str(start) + \"\\t\" + str(end) + \"\\n\")\n",
    "            \n",
    "        #getting the hg38 sequences for the 10 windows        \n",
    "        ref_seqs = !bedtools getfasta -fi /Volumes/BethMac/hg38/hg38.fa -bed sample_locations.tmp\n",
    "        \n",
    "        #loop once for each window\n",
    "        for i in range(1,len(ref_seqs),2):\n",
    "            #getting the seq\n",
    "            ref_seq= ref_seqs[i]\n",
    "            seq=copy.copy(ref_seq)\n",
    "            start=window_starts[i//2]\n",
    "            \n",
    "            #getting a list of tuples for each mutation within the window\n",
    "            nearby_mutations=[current_location]\n",
    "            for i in range(len(sample_mutations_dict[chrom])):\n",
    "                x = int(sample_mutations_dict[chrom][i][0])\n",
    "                if x > int(start) and x < (int(start) + 100) and x != int(current_location[1]):\n",
    "                    nearby_mutations.append(sample_mutations_dict[chrom][i])\n",
    "            \n",
    "            #add chrom names to mutation lists\n",
    "            for i in range(1,len(nearby_mutations)):\n",
    "                nearby_mutations[i] = [chrom]+nearby_mutations[i]\n",
    "                \n",
    "            #getting a list of tuples for possible normal variation within the window\n",
    "            nearby_variation=[]\n",
    "            for i in range(len(normal_var_dict[chrom])):\n",
    "                x = int(normal_var_dict[chrom][i][0])\n",
    "                if x > start and x < (start + 100):\n",
    "                    nearby_variation.append(normal_var_dict[chrom][i])\n",
    "            \n",
    "            #add chrom names to normal variation lists\n",
    "            for i in range(len(nearby_variation)):\n",
    "                nearby_variation[i] = [chrom]+nearby_variation[i]\n",
    "                    \n",
    "            #selecting which normal variation to include for the window\n",
    "            nearby_variation_random=[] \n",
    "            for i in range(len(nearby_variation)):\n",
    "                freq = nearby_variation[i][4]\n",
    "                if freq > 0.2:\n",
    "                    included = random.choices([nearby_variation[i], \"skip\"], weights=[freq, 1-freq], k=1)\n",
    "                else:\n",
    "                    included = random.choices([nearby_variation[i], \"skip\"], weights=[0.2, 0.8], k=1)\n",
    "                nearby_variation_random.append(included[0])\n",
    "            \n",
    "            #make changes and append sequence to files\n",
    "            \n",
    "            #the offset keeps track of effects of indels\n",
    "            offset=np.zeros(100).astype(int)\n",
    "        \n",
    "            #add in the nearby normal variation\n",
    "            for i in range(len(nearby_variation_random)):\n",
    "                seq, offset = update_sequence(nearby_variation_random, seq, offset, start)\n",
    "            \n",
    "            #if a big insertion leads to other variation outside the 100bp window those will \n",
    "            #append to the end and can be removed\n",
    "            if len(seq)>100:\n",
    "                seq=seq[:100]\n",
    "\n",
    "            with open('{}_normal.csv'.format(current_organ), 'a') as file:\n",
    "                file.write(current_sample + \",\" + seq + \",\" + ref_seq + \"\\n\")\n",
    "            \n",
    "            #add in the mutations on top of normal variation\n",
    "            for i in range(len(nearby_mutations)):\n",
    "                seq, offset = update_sequence(nearby_mutations, seq, offset, start)\n",
    "                \n",
    "            #if big insertion made a mutation was outside of the 100bp window it will have\n",
    "            #appeneded to the end. So there may be no mutation in the 100bp window and it should\n",
    "            #be discarded if over 100bp\n",
    "            if len(seq)==100:\n",
    "                with open('{}_tumor.csv'.format(current_organ), 'a') as file:\n",
    "                    file.write(current_sample + \",\" + seq + \",\" + ref_seq + \"\\n\")\n",
    "\n",
    "        !rm sample_locations.tmp\n",
    "        \n",
    "     \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('chr6', '47626538', 'C', 'C', 'A'),\n",
       " ('chr6', '52420447', 'C', 'C', 'T'),\n",
       " ('chr6', '53001844', 'G', 'G', 'A'),\n",
       " ('chr6', '53011913', 'C', 'C', 'G'),\n",
       " ('chr6', '56562135', 'C', 'C', 'A'),\n",
       " ('chr6', '73621919', 'G', 'G', 'C'),\n",
       " ('chr6', '90008607', 'C', 'C', 'G'),\n",
       " ('chr6', '93242465', 'G', 'G', 'T'),\n",
       " ('chr6', '96615760', 'C', 'C', 'A'),\n",
       " ('chr6', '108168060', 'G', 'G', 'C'),\n",
       " ('chr6', '112099347', 'G', 'G', 'A'),\n",
       " ('chr6', '129580081', 'C', 'C', 'G'),\n",
       " ('chr6', '136346031', 'C', 'C', 'G'),\n",
       " ('chr6', '137206225', 'G', 'G', 'C'),\n",
       " ('chr6', '143433832', 'C', 'C', 'G'),\n",
       " ('chr6', '143843376', 'G', 'G', 'A'),\n",
       " ('chr6', '144751813', 'G', 'G', 'C'),\n",
       " ('chr6', '151350204', 'G', 'G', 'A'),\n",
       " ('chr6', '154107953', 'TTTTTA', 'TTTTTA', '-'),\n",
       " ('chr6', '160046523', 'C', 'C', 'A'))"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mutations[250:270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_mutations=[('chr6', '154107953', 'TTTTTA', 'TTTTTA', '-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chr6', '154107953', 'TTTTTA', 'TTTTTA', '-')"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearby_mutations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = nearby_mutations[0][0]\n",
    "start = int(nearby_mutations[0][1]) -10\n",
    "end = start + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: temp_location.bed: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm temp_location.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_location.bed', 'w') as file:\n",
    "    file.write(chrom + \"\\t\" + str(start) + \"\\t\" + str(end))\n",
    "additional_sequence = !bedtools getfasta -fi /Volumes/BethMac/hg38/hg38.fa -bed temp_location.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = additional_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acactgatttttttattttattttattttattttattttattttattgccattcattcaaccgtttgcacagagagaaagaagacagaaatctgactggt'"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=np.zeros(100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('acactgattttttattttattttattttattttattttattgccattcattcaaccgtttgcacagagagaaagaagacagaaatctgactggtgactgg',\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6., -6.,\n",
       "        -6., -6., -6., -6., -6., -6., -6., -6., -6.]))"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_sequence(nearby_mutations, seq, offset, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "bioinformatics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
